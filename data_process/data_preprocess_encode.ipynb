{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "min_num_training = 0\n",
    "num_validation = 1\n",
    "include_user_features = False # add gender, age, shopping, occupation to the dataset (filters to users with this data available)\n",
    "include_ad_features = True # add category, brand, customer, campaign to the dataset (filters to ads with this data available)\n",
    "include_behavior_log = True\n",
    "include_ad_non_clks = True\n",
    "max_sequence_len = 100\n",
    "chunk_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params = f\"{min_num_training}_min_train_clks-{num_validation}_test_clks\"\n",
    "if include_user_features:\n",
    "    dataset_params += \"-usr_fts\"\n",
    "if include_ad_features:\n",
    "    dataset_params += \"-ad_fts\"\n",
    "if include_ad_non_clks:\n",
    "    dataset_params += \"-non_clks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feats = [\"user\"] + ([\"gender\", \"age\", \"shopping\", \"occupation\"] if include_user_features else [])\n",
    "ad_feats = [\"adgroup\"] + ([\"cate\", \"brand\", \"campaign\", \"customer\"] if include_ad_features else [])\n",
    "pretraining_ad_feats = set([\"cate\", \"brand\"]).intersection(set(ad_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sample = (pl\n",
    "    .scan_parquet(os.path.join(data_dir, \"raw_sample.parquet\"))\n",
    "    .filter(pl.col(\"clk\") == True)\n",
    "    .filter(pl.len().over(\"user\") >= min_num_training + num_validation)\n",
    "    .unique([\"user\", \"adgroup\", \"timestamp\"])\n",
    ")\n",
    "if include_user_features:\n",
    "    raw_sample = raw_sample.join(\n",
    "        other=pl.scan_parquet(os.path.join(data_dir, \"user_profile.parquet\")).select(user_feats),\n",
    "        on=\"user\", how=\"inner\",\n",
    "    )\n",
    "if include_ad_features:\n",
    "    raw_sample = raw_sample.join(\n",
    "        other=pl.scan_parquet(os.path.join(data_dir, \"ad_feature.parquet\")).select(ad_feats),\n",
    "        on=\"adgroup\", how=\"inner\",\n",
    "    )\n",
    "raw_sample = raw_sample.collect()\n",
    "raw_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = (\n",
    "    raw_sample\n",
    "    .filter(pl.len().over(\"user\") > num_validation)\n",
    "    .sort(\"user\", \"timestamp\", nulls_last=True)\n",
    "    .group_by(\"user\", maintain_order=True)\n",
    "    .agg(pl.all().head(pl.len() - num_validation))\n",
    "    .explode(pl.all().exclude(\"user\"))\n",
    "    .select(*user_feats, *ad_feats, pl.lit(1).alias(\"btag\").cast(pl.Int8), \"timestamp\")\n",
    ")\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = (\n",
    "    raw_sample\n",
    "    .sort(\"user\", \"timestamp\", nulls_last=True)\n",
    "    .group_by(\"user\", maintain_order=True)\n",
    "    .agg(pl.all().tail(num_validation))\n",
    "    .explode(pl.all().exclude(\"user\"))\n",
    "    .select(*user_feats, *ad_feats, pl.lit(1).alias(\"btag\").cast(pl.Int8), \"timestamp\")\n",
    ")\n",
    "validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data.join(training_data, on=[\"user\", \"adgroup\"], how=\"inner\") \\\n",
    "    .filter(pl.col(\"timestamp\") <= pl.col(\"timestamp_right\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_validation_click = (\n",
    "    validation_data.select(\"user\", pl.col(\"timestamp\").alias(\"first_validation_ad_click_time\"))\n",
    "    .sort(\"user\", \"first_validation_ad_click_time\", nulls_last=True)\n",
    "    .group_by(\"user\", maintain_order=True).head(1)\n",
    ")\n",
    "first_validation_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = (training_data\n",
    "    .join(first_validation_click, on = \"user\")\n",
    "    .filter(pl.col(\"timestamp\") < pl.col(\"first_validation_ad_click_time\"))\n",
    "    .select(pl.all().exclude(\"first_validation_ad_click_time\"))\n",
    ")\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_behavior_log and (\"cate\" in ad_feats or \"brand\" in ad_feats):\n",
    "    # Loading takes ~30s for pretraining dataset from behavior log\n",
    "    behavior_log = (pl\n",
    "        .scan_parquet(os.path.join(data_dir, \"behavior_log.parquet\"))\n",
    "        .filter(pl.col(\"user\").is_in(raw_sample.select(\"user\").unique()))\n",
    "    )\n",
    "    if include_user_features:\n",
    "        behavior_log = behavior_log.join(\n",
    "            other=pl.scan_parquet(os.path.join(data_dir, \"user_profile.parquet\")).select(user_feats),\n",
    "            on=\"user\", how=\"inner\",\n",
    "        )\n",
    "    behavior_log = (behavior_log.collect()\n",
    "        .join(first_validation_click, on=\"user\", how=\"inner\")\n",
    "        .filter(pl.col(\"timestamp\") < pl.col(\"first_validation_ad_click_time\"))\n",
    "        .unique()\n",
    "        .select(*user_feats, *pretraining_ad_feats, pl.col(\"btag\").cast(pl.Int8), \"timestamp\")\n",
    "    )\n",
    "    training_data = pl.concat([training_data, behavior_log], how=\"diagonal\")\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_users = training_data.select(\"user\").unique()\n",
    "validation_data = validation_data.filter(pl.col(\"user\").is_in(valid_users))\n",
    "validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_ad_non_clks:\n",
    "    negatives = (pl\n",
    "        .scan_parquet(os.path.join(data_dir, \"raw_sample.parquet\"))\n",
    "        .filter((pl.col(\"clk\") == False) & (pl.col(\"user\").is_in(valid_users))).collect()\n",
    "        .join(first_validation_click, on=\"user\", how=\"inner\")\n",
    "        .filter(pl.col(\"timestamp\") < pl.col(\"first_validation_ad_click_time\"))\n",
    "        .unique([\"user\", \"adgroup\", \"timestamp\"])\n",
    "    )\n",
    "    if include_user_features:\n",
    "        negatives = negatives.join(\n",
    "            other=pl.read_parquet(os.path.join(data_dir, \"user_profile.parquet\")).select(user_feats),\n",
    "            on=\"user\", how=\"inner\",\n",
    "        )\n",
    "    if include_ad_features:\n",
    "        negatives = negatives.join(\n",
    "            other=pl.read_parquet(os.path.join(data_dir, \"ad_feature.parquet\")).select(ad_feats),\n",
    "            on=\"adgroup\", how=\"inner\",\n",
    "        )\n",
    "    negatives = (negatives\n",
    "        .select(*user_feats, *ad_feats, pl.lit(-1).alias(\"btag\").cast(pl.Int8), \"timestamp\")\n",
    "    )\n",
    "    training_data = pl.concat([training_data, negatives])\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profile = validation_data.select(user_feats).unique()\n",
    "user_encoder = OrdinalEncoder(dtype=np.int32).fit(user_profile)\n",
    "user_encoder.set_output(transform=\"polars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_feature: pl.DataFrame = pl.concat([\n",
    "    training_data.select(ad_feats).unique(),\n",
    "    validation_data.select(ad_feats).unique(),\n",
    "]).unique()\n",
    "ad_encoder = OrdinalEncoder(dtype=np.int32, encoded_missing_value=-1).fit(ad_feature)\n",
    "ad_encoder.set_output(transform=\"polars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = user_encoder.transform(training_data.select(user_feats))\n",
    "ads_data = ad_encoder.transform(training_data.select(ad_feats))\n",
    "interaction_data = training_data.select(\"btag\", pl.col(\"timestamp\").cast(pl.Int32), is_test = pl.lit(False))\n",
    "training_data = pl.concat([user_data, ads_data, interaction_data], how=\"horizontal\")\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = user_encoder.transform(validation_data.select(user_feats))\n",
    "ads_data = ad_encoder.transform(validation_data.select(ad_feats))\n",
    "interaction_data = validation_data.select(\"btag\", pl.col(\"timestamp\").cast(pl.Int32), is_test = pl.lit(True))\n",
    "validation_data = pl.concat([user_data, ads_data, interaction_data], how=\"horizontal\")\n",
    "validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profile.write_parquet(os.path.join(data_dir, f\"user_profile-{dataset_params}.parquet\"))\n",
    "ad_feature.write_parquet(os.path.join(data_dir, f\"ad_feature-{dataset_params}.parquet\"))\n",
    "training_data.write_parquet(os.path.join(data_dir, f\"train-{dataset_params}.parquet\"))\n",
    "validation_data.write_parquet(os.path.join(data_dir, f\"test-{dataset_params}.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ad_click = min_num_training + num_validation\n",
    "user_profile.write_parquet(os.path.join(data_dir, f\"user_profile_{min_ad_click}.parquet\"))\n",
    "ad_feature.write_parquet(os.path.join(data_dir, f\"ad_feature_{min_ad_click}.parquet\"))\n",
    "training_data.write_parquet(os.path.join(data_dir, f\"train_{min_ad_click}.parquet\"))\n",
    "validation_data.write_parquet(os.path.join(data_dir, f\"test_{min_ad_click}.parquet\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions: pl.DataFrame = (pl\n",
    "    .concat([training_data, validation_data])\n",
    "    .with_columns(rel_ad_freq = (pl.len().over(\"adgroup\") / pl.count(\"adgroup\")).cast(pl.Float32))\n",
    ")\n",
    "rel_ad_freq_sum = interactions.select(\"adgroup\", \"rel_ad_freq\").unique().select(\"rel_ad_freq\").sum().item()\n",
    "print(\"Relative Ad Frequency Sanity Check Sum:\", rel_ad_freq_sum)\n",
    "sequences = (interactions\n",
    "    .sort(\"user\", \"timestamp\")\n",
    "    .group_by(\"user\", maintain_order=True)\n",
    "    .agg(\n",
    "        pl.col(user_feats[1:]).first(),\n",
    "        pl.col(*ad_feats, \"rel_ad_freq\", \"btag\", \"timestamp\", \"is_test\"),\n",
    "        seq_len = pl.col(\"btag\").len()\n",
    "    )\n",
    ")\n",
    "max_seq_len = sequences.select(pl.col(\"seq_len\").max()).item()\n",
    "print(\"Maximum sequence length:\", max_seq_len)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_seq = (sequences\n",
    "    .with_columns(pad_len = max_seq_len - pl.col(\"seq_len\"))\n",
    "    .select(\n",
    "        pl.col(user_feats),\n",
    "        pl.col(\"seq_len\"),\n",
    "        pl.col(\"pad_len\"),\n",
    "        *(\n",
    "            pl.col(feat).list.concat(pl.lit(0).repeat_by(pl.col(\"pad_len\"))).list.to_array(max_seq_len)\n",
    "            for feat in [*ad_feats, \"rel_ad_freq\", \"btag\", \"timestamp\"]\n",
    "        ),\n",
    "        pl.col(\"is_test\").list.concat(pl.lit(False).repeat_by(pl.col(\"pad_len\"))).list.to_array(max_seq_len),\n",
    "        padded_mask = (pl.lit(False).repeat_by(pl.col(\"seq_len\"))\n",
    "          .list.concat(pl.lit(True).repeat_by(pl.col(\"pad_len\")))\n",
    "          .list.to_array(max_seq_len)\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions.write_parquet(os.path.join(data_dir, f\"interactions_{min_ad_click}.parquet\"))\n",
    "interaction_seq.write_parquet(os.path.join(data_dir, f\"interaction_seq_{min_ad_click}.parquet\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
