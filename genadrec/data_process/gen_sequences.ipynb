{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(\"..\", \"data\")\n",
    "train_parquet = os.path.join(data_dir, \"train.parquet\")\n",
    "test_parquet = os.path.join(data_dir, \"test.parquet\")\n",
    "min_timediff_unique = 30        # The minimum number of seconds between identical interactions (user, adgroup, btag), or (user, cate, brand, btag), before they are considered duplicates\n",
    "min_training_interactions = 5   # The minimum number of non-ad-click, browse, ad-click, favorite, add-to-cart, or purchase interactions a user must have to be included\n",
    "sequence_len = 100\n",
    "slide_window_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feats = [\"user\", \"gender\", \"age\", \"shopping\", \"occupation\"]\n",
    "ad_feats = [\"adgroup\", \"cate\", \"brand\", \"campaign\", \"customer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = (pl.scan_parquet(train_parquet)\n",
    "    .filter(pl.col(\"timediff\").is_null() | (pl.col(\"timediff\") >= min_timediff_unique))\n",
    "    .filter(pl.len().over(\"user\") >= min_training_interactions)\n",
    "    .collect()\n",
    ")\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = (pl.scan_parquet(test_parquet)\n",
    "    .filter(pl.col(\"user\").is_in(training_data.select(\"user\").unique()))\n",
    "    .collect()\n",
    ")\n",
    "validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions: pl.DataFrame = pl.concat([training_data, validation_data], how=\"vertical\")\n",
    "rel_ad_freqs = (interactions\n",
    "    .filter(pl.col(\"adgroup\") > -1)\n",
    "    .select(\"adgroup\", rel_ad_freq = (pl.len().over(\"adgroup\") / pl.count(\"adgroup\")).cast(pl.Float32))\n",
    "    .unique()\n",
    ")\n",
    "rel_ad_freq_sum = rel_ad_freqs.select(\"rel_ad_freq\").sum().item()\n",
    "print(\"Relative Ad Frequency Sanity Check Sum:\", rel_ad_freq_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = (interactions\n",
    "    .join(rel_ad_freqs, on=\"adgroup\", how=\"left\")\n",
    "    .group_by(\"user\")\n",
    "    .agg(\n",
    "        pl.col(user_feats[1:]).first(),\n",
    "        pl.col(*ad_feats, \"rel_ad_freq\", \"btag\", \"timestamp\", \"is_test\").sort_by(\"timestamp\"),\n",
    "        seq_len = pl.col(\"btag\").len().cast(pl.Int32)\n",
    "    )\n",
    "    .with_columns(pl.col(\"timestamp\").list.diff())\n",
    ")\n",
    "min_seq_len = sequences.select(pl.col(\"seq_len\").min()).item()\n",
    "max_seq_len = sequences.select(pl.col(\"seq_len\").max()).item()\n",
    "print(\"Minimum sequence length:\", min_seq_len)\n",
    "print(\"Maximum sequence length:\", max_seq_len)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = pl.concat([\n",
    "    (sequences\n",
    "        .filter(pl.col(\"seq_len\") > abs(end_idx))\n",
    "        .select(\n",
    "            pl.col(user_feats),\n",
    "            pl.col(*ad_feats, \"rel_ad_freq\", \"btag\", \"timestamp\", \"is_test\")\n",
    "                .list.gather(range(end_idx-sequence_len, end_idx), null_on_oob=True)\n",
    "                .list.shift(pl.min_horizontal(pl.col(\"seq_len\") + (end_idx-sequence_len), 0))\n",
    "                .list.to_array(sequence_len),\n",
    "            seq_len = pl.min_horizontal(pl.col(\"seq_len\") + end_idx, sequence_len).cast(pl.Int32)\n",
    "        )\n",
    "    ) for end_idx in range(-1, -max_seq_len, -slide_window_every)\n",
    "], how=\"vertical\").filter(pl.col(\"seq_len\") >= min_training_interactions)\n",
    "train_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = (sequences.select(\n",
    "    pl.col(user_feats),\n",
    "    pl.col(*ad_feats, \"rel_ad_freq\", \"btag\", \"timestamp\", \"is_test\")\n",
    "        .list.gather(range(-sequence_len, 0), null_on_oob=True)\n",
    "        .list.shift(pl.min_horizontal(pl.col(\"seq_len\") - sequence_len, 0))\n",
    "        .list.to_array(sequence_len),\n",
    "    seq_len = pl.min_horizontal(pl.col(\"seq_len\"), sequence_len).cast(pl.Int32)\n",
    "))\n",
    "test_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences.write_parquet(os.path.join(data_dir, \"train_sequences.parquet\"))\n",
    "test_sequences.write_parquet(os.path.join(data_dir, \"test_sequences.parquet\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
