{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(\"..\", \"data\")\n",
    "train_parquet = os.path.join(data_dir, \"train.parquet\")\n",
    "test_parquet = os.path.join(data_dir, \"test.parquet\")\n",
    "min_timediff_unique = 30        # The minimum number of seconds between identical interactions (user, adgroup, btag), or (user, cate, brand, btag), before they are considered duplicates\n",
    "min_training_interactions = 5   # The minimum number of non-ad-click, browse, ad-click, favorite, add-to-cart, or purchase interactions required in a training sequence\n",
    "augmented = False               # Whether to include behavior log interaction data or not\n",
    "sequence_len = 128\n",
    "slide_window_every = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence_params = f\"timediff{min_timediff_unique}_mintrain{min_training_interactions}_seqlen{sequence_len}_slide{slide_window_every}\" + (\"_aug\" if augmented else \"\")\n",
    "test_sequence_params = f\"timediff{min_timediff_unique}_mintrain{min_training_interactions}_seqlen{sequence_len}\" + (\"_aug\" if augmented else \"\")\n",
    "user_feats = [\"user\", \"gender\", \"age\", \"shopping\", \"occupation\"]\n",
    "ad_feats = [\"adgroup\", \"cate\", \"brand\", \"campaign\", \"customer\"]\n",
    "full_ad_feats = ad_feats + [\"rel_ad_freq\", \"btag\", \"timestamp\", \"is_test\"]\n",
    "selected_feats = [*user_feats, *full_ad_feats, \"seq_len\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = (pl.scan_parquet(train_parquet)\n",
    "    .filter((pl.col(\"timediff\").is_null() | (pl.col(\"timediff\") >= min_timediff_unique)) &\n",
    "            ((pl.col(\"btag\").is_in([-1, 1])) if not augmented else True))\n",
    "    .filter(pl.len().over(\"user\") >= min_training_interactions)\n",
    "    .collect()\n",
    ")\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = (pl.scan_parquet(test_parquet)\n",
    "    .filter(pl.col(\"user\").is_in(training_data.select(\"user\").unique()))\n",
    "    .collect()\n",
    ")\n",
    "validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions: pl.DataFrame = pl.concat([training_data, validation_data], how=\"vertical\", rechunk=True)\n",
    "del training_data, validation_data\n",
    "interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_ad_freqs = (interactions\n",
    "    .filter(pl.col(\"adgroup\") > -1)\n",
    "    .select(\"adgroup\", rel_ad_freq = (pl.len().over(\"adgroup\") / pl.count(\"adgroup\")).cast(pl.Float32))\n",
    "    .unique()\n",
    ")\n",
    "rel_ad_freq_sum = rel_ad_freqs.select(\"rel_ad_freq\").sum().item()\n",
    "print(\"Relative Ad Frequency Sanity Check Sum:\", rel_ad_freq_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = (interactions\n",
    "    .join(rel_ad_freqs, on=\"adgroup\", how=\"left\")\n",
    "    .with_columns(pl.col(\"rel_ad_freq\").fill_null(0.0))\n",
    "    .group_by(\"user\")\n",
    "    .agg(\n",
    "        pl.col(user_feats[1:]).first(),\n",
    "        pl.col(full_ad_feats).sort_by(\"timestamp\"),\n",
    "        seq_len = pl.col(\"btag\").len().cast(pl.Int32)\n",
    "    )\n",
    "    .with_columns(pl.col(\"timestamp\").list.diff().list.eval(pl.element().fill_null(0)))\n",
    ")\n",
    "del interactions, rel_ad_freqs\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_seq_len = sequences.select(pl.col(\"seq_len\").min()).item()\n",
    "max_seq_len = sequences.select(pl.col(\"seq_len\").max()).item()\n",
    "print(\"Minimum sequence length:\", min_seq_len)\n",
    "print(\"Maximum sequence length:\", max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = (pl\n",
    "    .concat([\n",
    "        (sequences\n",
    "            .filter((pl.col(\"seq_len\") + end_idx > sequence_len - slide_window_every) if end_idx < -1 else True)\n",
    "            .select(\n",
    "                pl.col(user_feats),\n",
    "                pl.col(full_ad_feats)\n",
    "                    .list.gather(range(end_idx-sequence_len, end_idx), null_on_oob=True)\n",
    "                    .list.shift(pl.min_horizontal(pl.col(\"seq_len\") + (end_idx-sequence_len), 0)),\n",
    "                seq_len = pl.min_horizontal(pl.col(\"seq_len\") + end_idx, sequence_len).cast(pl.Int32)\n",
    "            )\n",
    "        ) for end_idx in range(-1, -max_seq_len, -slide_window_every)\n",
    "    ], how=\"vertical\")\n",
    "    .filter(pl.col(\"seq_len\") >= min_training_interactions)\n",
    "    .with_columns(\n",
    "        pl.col(ad_feats).list.eval(pl.element().fill_null(-1)).list.to_array(sequence_len),\n",
    "        pl.col(\"rel_ad_freq\").list.eval(pl.element().fill_null(0.0)).list.to_array(sequence_len),\n",
    "        pl.col(\"btag\").list.eval(pl.element().fill_null(-2)).list.to_array(sequence_len),\n",
    "        pl.col(\"timestamp\").list.eval(pl.element().fill_null(0)).list.to_array(sequence_len),\n",
    "        pl.col(\"is_test\").list.eval(pl.element().fill_null(True)).list.to_array(sequence_len),\n",
    "    )\n",
    ")\n",
    "train_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = (sequences\n",
    "    .select(\n",
    "        pl.col(user_feats),\n",
    "        pl.col(full_ad_feats)\n",
    "            .list.gather(range(-sequence_len, 0), null_on_oob=True)\n",
    "            .list.shift(pl.min_horizontal(pl.col(\"seq_len\") - sequence_len, 0)),\n",
    "        seq_len = pl.min_horizontal(pl.col(\"seq_len\"), sequence_len).cast(pl.Int32)\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(ad_feats).list.eval(pl.element().fill_null(-1)).list.to_array(sequence_len),\n",
    "        pl.col(\"rel_ad_freq\").list.eval(pl.element().fill_null(0.0)).list.to_array(sequence_len),\n",
    "        pl.col(\"btag\").list.eval(pl.element().fill_null(-2)).list.to_array(sequence_len),\n",
    "        pl.col(\"timestamp\").list.eval(pl.element().fill_null(0)).list.to_array(sequence_len),\n",
    "        pl.col(\"is_test\").list.eval(pl.element().replace(True, False))\n",
    "                         .list.eval(pl.element().fill_null(True)).list.to_array(sequence_len),\n",
    "    )\n",
    ")\n",
    "test_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\n",
    "    file = os.path.join(data_dir, f\"train_data_{train_sequence_params}\"),\n",
    "    user_data = train_sequences.select(user_feats).to_numpy(),\n",
    "    **{feat: train_sequences[feat].to_numpy() for feat in ad_feats},\n",
    "    rel_ad_freqs = train_sequences[\"rel_ad_freq\"].to_numpy(),\n",
    "    interaction_data = train_sequences[\"btag\"].to_numpy(),\n",
    "    timestamps = train_sequences[\"timestamp\"].to_numpy(),\n",
    "    padded_masks = train_sequences[\"is_test\"].to_numpy(),\n",
    "    seq_lens = train_sequences[\"seq_len\"].to_numpy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\n",
    "    file = os.path.join(data_dir, f\"test_data_{test_sequence_params}\"),\n",
    "    user_data = test_sequences.select(user_feats).to_numpy(),\n",
    "    **{feat: test_sequences[feat].to_numpy() for feat in ad_feats},\n",
    "    rel_ad_freqs = test_sequences[\"rel_ad_freq\"].to_numpy(),\n",
    "    interaction_data = test_sequences[\"btag\"].to_numpy(),\n",
    "    timestamps = test_sequences[\"timestamp\"].to_numpy(),\n",
    "    padded_masks = test_sequences[\"is_test\"].to_numpy(),\n",
    "    seq_lens = test_sequences[\"seq_len\"].to_numpy(),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
